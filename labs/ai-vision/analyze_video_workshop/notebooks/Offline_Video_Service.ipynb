{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "222552d2",
   "metadata": {},
   "source": [
    "\n",
    "# <b>Offline Video Service Demo</b>\n",
    "\n",
    "\n",
    "The AIServiceVisionClient offers the video features. This notebook aims to provide overall clarity about the features to the user in terms of requirements, usage.\n",
    "<ul>\n",
    "    <li><font size=\"2\">The output response file is stored at the object storage location specified in the below cells.</font></li>\n",
    "    <li><font size=\"2\">At the end of the notebook the response is downloaded and saved as <code>video_response.json</code> in the output directory. </font></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afbd40c",
   "metadata": {},
   "source": [
    "### Steps to run the notebook:\n",
    "<details>\n",
    "    <summary>Notebook session setup</summary>\n",
    "    <ol>\n",
    "        <li><font size=\"2\">Installing the OCI SDK</font></li>\n",
    "        <li><font size=\"2\">Installing other dependencies</font></li>\n",
    "        <li><font size=\"2\">Setup sample input images</font></li>\n",
    "        <li><font size=\"2\">Create output folder</font></li>\n",
    "        <li><font size=\"2\">Setup helper .py files</font></li>\n",
    "    </ol>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>Importing the required modules</summary>\n",
    "    <ol>\n",
    "    </ol>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>Setting the input variables</summary>\n",
    "    <ol>\n",
    "        <li><font size=\"2\">The user can give input variables of their choice.</font></li>\n",
    "    </ol>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>Running the main pipeline</summary>\n",
    "    <ol>\n",
    "        <li><font size=\"2\">Run all cells to get the output in the <code>output</code> directory. </font><br></li>\n",
    "    </ol>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba246b2",
   "metadata": {},
   "source": [
    "### Notebook session setup\n",
    "<details>\n",
    "    <summary>Instructions</summary>\n",
    "    <ul>\n",
    "        <li><font size=\"2\">The user needs to setup only once.</font></li>\n",
    "        <li><font size=\"2\">Uncomment the commented cells and run once to setup.</font></li>\n",
    "        <li><font size=\"2\">Comment back the same cells to avoid running again.</font></li>\n",
    "    </ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f89d12",
   "metadata": {},
   "source": [
    "#### Installing the OCI Python SDK\n",
    "Contact OCI AI Vision team to get access to preview SDK. Download and run the below command to install python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35010c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please use pip/pip3 as per availability\n",
    "# !pip3 install 2.115.2+preview.1.1678-py2.py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbca395d",
   "metadata": {},
   "source": [
    "#### Setup sample input\n",
    "\n",
    "* Uncomment and run the cell below.\n",
    "* Create a bucket in your tenancy (you may skip this step if you have an existing bucket)\n",
    "* Upload the video `demo.mp4` to the bucket. (you can also upload and use the video of your choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a94b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget \"https://github.com/oracle-samples/oci-data-science-ai-samples/tree/main/labs/ai-vision/analyze_video_workshop/data/demo.mp4\"\n",
    "# !mkdir data\n",
    "# !mv demo.mp4 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4277c4",
   "metadata": {},
   "source": [
    "#### Setup helper.py files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba3329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget \"https://github.com/oracle-samples/oci-data-science-ai-samples/tree/main/labs/ai-vision/analyze_video_workshop/helper/analyze_video_utils.py\"\n",
    "# !mkdir helper\n",
    "# !mv analyze_video_utils.py helper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a46d5e",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12753a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import oci\n",
    "from oci.ai_vision.models import *\n",
    "from helper.analyze_video_utils import display_formatted_response\n",
    "from IPython.display import JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd4dd46",
   "metadata": {},
   "source": [
    "#### Authorize OCI config\n",
    "Set up authentication for OCI by reading configuration from a file. The default configuration file location is ```~/.oci/config``` and ```DEFAULT``` profile is choosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bafd21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = oci.config.from_file('~/.oci/config', profile_name='DEFAULT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f561b1",
   "metadata": {},
   "source": [
    "#### Set required input variables\n",
    "<details>\n",
    "    <summary><font size=\"3\">input_location_variables</font></summary>\n",
    "    <font size=\"2\">The user needs to provide the following details:\n",
    "        <ul>\n",
    "            <li><code>namespace</code> : specify the namespace where the input video is uploaded</li>\n",
    "            <li><code>bucket</code> : specify the bucket name where the input video is uploaded</li>\n",
    "            <li><code>filename</code> : specify the filename of the input video(e.g: we have uploaded <code>demo.mp4</code> in <code>Setup sample input</code> step )</li>\n",
    "        </ul>\n",
    "    </font>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary><font size=\"3\">output_location_path</font></summary>\n",
    "    <font size=\"2\">The user needs to provide the following details to store the output:\n",
    "        <ul>\n",
    "            <li><code>namespace</code> : specify the namespace where the output has to be stored</li>\n",
    "            <li><code>bucket</code> : specify the bucket name where the output has to be stored</li>\n",
    "            <li><code>prefix</code> : specify the prefix where the output has to be stored</li>\n",
    "        </ul>\n",
    "    </font>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><font size=\"3\">compartment_id</font></summary>\n",
    "    <font size=\"2\">The user should provide the compartment OCID to call the API.</font><br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e9495",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_namespace = \"<INPUT_NAMESPACE>\"\n",
    "input_bucket = \"<INPUT_BUCKET>\"\n",
    "input_filename = \"<INPUT_FILENAME>\"\n",
    "\n",
    "output_namespace = \"<OUTPUT_NAMESPACE>\"\n",
    "output_bucket = \"<OUTPUT_BUCKET>\"\n",
    "output_prefix = \"<OUTPUT_PREFIX>\"\n",
    "\n",
    "compartment_id = \"<COMPARTMENT_ID>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce24213",
   "metadata": {},
   "source": [
    "#### Set optional input variables\n",
    "\n",
    "<details>\n",
    "<summary><font size=\"3\">max_results</font></summary>\n",
    "    <font size=\"2\">Provide the maximum results needed for Object, Label and Face Detection. This is an upper limit over the output classes, the API may detect lesser classes according to the input video. In case of Object and Label Detection default value is 5. Whereas for Face Detection default value is 50 </font><br>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><font size=\"3\">min_confidence</font></summary>\n",
    "    <font size=\"2\">Provide the minimum confidence needed for the feature. This is an lower limit over the output, the API may detect objects and classes above the specified confidence. Default value is 0</font><br>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><font size=\"3\">model_id</font></summary>\n",
    "    <font size=\"2\">In case of custom models uncomment the line and provide the model_id needed for the feature.</font><br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2325fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_results = 5\n",
    "\n",
    "min_confidence = 0 \n",
    "\n",
    "# model_id = \"<MODEL_ID>\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b4c1dd",
   "metadata": {},
   "source": [
    "#### Setup input location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf14ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_location_1 = ObjectLocation()\n",
    "object_location_1.namespace_name = input_namespace\n",
    "object_location_1.bucket_name = input_bucket\n",
    "object_location_1.object_name = input_filename\n",
    "object_locations = [object_location_1]\n",
    "input_location = ObjectListInlineInputLocation()\n",
    "input_location.object_locations = object_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febcec9f",
   "metadata": {},
   "source": [
    "#### Setup output location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7659cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_location = OutputLocation()\n",
    "output_location.namespace_name = output_namespace\n",
    "output_location.bucket_name = output_bucket\n",
    "output_location.prefix = output_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca5761",
   "metadata": {},
   "source": [
    "### Create AIServiceVisionClient and Setup input feature for Offline video features\n",
    "You can specify the features you want to call. In the below code all supported pretrained models are called. To call custom models uncomment commented lines and replace your model id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e27b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_service_vision_client = oci.ai_vision.AIServiceVisionClient(config=config)\n",
    "\n",
    "video_label_detection_feature = VideoLabelDetectionFeature()\n",
    "video_label_detection_feature.max_results = max_results\n",
    "video_label_detection_feature.min_confidence = min_confidence\n",
    "# video_label_detection_feature.model_id = model_id\n",
    "\n",
    "video_object_detection_feature = VideoObjectDetectionFeature()\n",
    "video_object_detection_feature.max_results = max_results\n",
    "video_object_detection_feature.min_confidence = min_confidence\n",
    "# video_object_detection_feature.model_id = model_id\n",
    "\n",
    "video_text_detection_feature = VideoTextDetectionFeature()\n",
    "video_text_detection_feature.min_confidence = min_confidence\n",
    "\n",
    "video_face_detection_feature = VideoFaceDetectionFeature()\n",
    "video_face_detection_feature.max_results = max_results\n",
    "video_face_detection_feature.min_confidence = min_confidence\n",
    "\n",
    "features = [video_label_detection_feature, \n",
    "            video_object_detection_feature, \n",
    "            video_text_detection_feature, \n",
    "            video_face_detection_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da59ec19",
   "metadata": {},
   "source": [
    "### Create video job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e27e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_video_job_details = CreateVideoJobDetails()\n",
    "create_video_job_details.features = features\n",
    "create_video_job_details.compartment_id = compartment_id\n",
    "create_video_job_details.output_location = output_location\n",
    "create_video_job_details.input_location = input_location\n",
    "\n",
    "res = ai_service_vision_client.create_video_job(create_video_job_details=create_video_job_details)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cb3c3e",
   "metadata": {},
   "source": [
    "### Job submitted\n",
    "The job is created and should be in <code>ACCEPTED</code> state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1423b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON(display_formatted_response(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f153e0",
   "metadata": {},
   "source": [
    "#### Job IN_PROGRESS\n",
    "The job progress is tracked till completion with a polling interval of 5 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a695df",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = res.data.id\n",
    "polling_interval = 5\n",
    "print(\"Job ID :\", job_id, '\\n')\n",
    "seconds = 0\n",
    "while res.data.lifecycle_state == \"IN_PROGRESS\" or res.data.lifecycle_state == \"ACCEPTED\":\n",
    "    print(f\"Job {job_id} is IN_PROGRESS for {str(seconds)} seconds, progress: {res.data.percent_complete}\")\n",
    "    time.sleep(polling_interval)\n",
    "    seconds += polling_interval\n",
    "    res = ai_service_vision_client.get_video_job(video_job_id=job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2db11dc",
   "metadata": {},
   "source": [
    "### Job completed\n",
    "The job is completed and should be in <code>SUCCEEDED</code> state. In case the job is not in <code>SUCCEEDED</code> state refer to the displayed response below to know the state and reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec073627",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON(display_formatted_response(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba42d96",
   "metadata": {},
   "source": [
    "#### Get response json from object storage\n",
    "The output can be found in the output location specified or it can be saved in ```video_response.json``` file by running the below cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaa46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_storage_client = oci.object_storage.ObjectStorageClient(config)\n",
    "output_object_name = f\"{output_location.prefix}/{job_id}/{input_location.object_name}.json\"\n",
    "\n",
    "video_response = object_storage_client.get_object(output_location.namespace_name, output_location.bucket_name, output_object_name)\n",
    "\n",
    "file = open('video_response.json', 'w')\n",
    "file.write(video_response.data.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
